{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.wkt import loads\n",
    "import torch_geometric\n",
    "import random \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning Regular, Tabular Data into Graph-Structured Data\n",
    "Our data is initially formatted as a table of emissions readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coal_mining = pd.read_csv('data/fossil-fuels/asset_coal-mining_emissions.csv')\n",
    "coal_mining['coords'] = coal_mining['st_astext'].apply(lambda x: loads(x).coords[0])\n",
    "coal_mining.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each emission site has 5 readings - one for each gas type (co2, ch4, n2o, co2e_100yr, co2e_20yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coal_mining.asset_id.value_counts().unique() # There are exactly 5 occurences of every ID - no more no less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can filter the dataframe to just one of these to draw our edges, since each of the 5 readings represents the same site in the same location, just a different gas. Before we do that, we can map the IDs from a (m-n) range to (0-k) where k = # unique asset IDs - 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_id_mapping(ids):\n",
    "    '''\n",
    "    Arg(s):\n",
    "        ids - numpy.ndarray of UNIQUE asset_ids of unknown range and length\n",
    "    Output:\n",
    "        id_mapping - dictionary where\n",
    "            key: original asset_id from df (e.g. 136113483)\n",
    "            val: ID in range 0-k, where k = # of unique IDs - 1.\n",
    "    '''\n",
    "    id_mapping = {}\n",
    "    for i, asset in enumerate(ids):\n",
    "        id_mapping[asset] = i\n",
    "    \n",
    "    return id_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = coal_mining.asset_id.unique()\n",
    "id_mapping = generate_id_mapping(unique_ids)\n",
    "\n",
    "coal_mining['asset_id'] = coal_mining['asset_id'].apply(lambda x: id_mapping[x])\n",
    "coal_mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will filter to only one gas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coal_ch4_emissions = coal_mining[coal_mining['gas'] == 'ch4']\n",
    "coal_ch4_emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start drawing edges using Haversine distance. First, we pull out id-coord pairs - like (id, (lat,lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_coord_pairs = list(zip(coal_ch4_emissions['asset_id'], coal_ch4_emissions['coords']))\n",
    "id_coord_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can establish our distance metric - Haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(pt1, pt2):\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1 = math.radians(pt1[1])\n",
    "    lon1 = math.radians(pt1[0])\n",
    "    lat2 = math.radians(pt2[1])\n",
    "    lon2 = math.radians(pt2[0])\n",
    "\n",
    "    # Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "    distance = 6371.0 * c  # Radius of the Earth in kilometers (you can use 3959.0 for miles)\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_nodes(id_coord_pairs, distance_threshold):\n",
    "    '''\n",
    "    Arg(s):\n",
    "        id_coord_pairs: A list of tuples containing\n",
    "            - a normalized asset ID, e.g. 4\n",
    "            - a tuple lat-lon pair, e.g. (100, 30)\n",
    "    Output:\n",
    "        edge_index: A 2xN tensor representing every edge. Think of the first row \n",
    "        as all the starting points of each edge, and the second row as the finish point\n",
    "    '''\n",
    "    start_of_edges = []\n",
    "    end_of_edges = []\n",
    "\n",
    "    for pair_a in id_coord_pairs:\n",
    "        id_a = pair_a[0]\n",
    "        coords_a = pair_a[1]\n",
    "        for pair_b in id_coord_pairs:\n",
    "            id_b = pair_b[0]\n",
    "            coords_b = pair_b[1]\n",
    "            if id_a != id_b:\n",
    "                distance = haversine(coords_a, coords_b)\n",
    "                if distance < distance_threshold:\n",
    "                    start_of_edges.append(id_a)\n",
    "                    end_of_edges.append(id_b)\n",
    "\n",
    "    edge_index = [start_of_edges, end_of_edges]\n",
    "    return torch.tensor(edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will aggregate all of this into a function that can take in a csv of data and save a bunch of corresponding edge indices based on distances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_data_and_edges(df, distances, object_folder_path, gas=None):\n",
    "    '''\n",
    "    Inputs:\n",
    "        df (pd.Dataframe)\n",
    "            -processed dataframe (i.e. number of rows finalized, time granularities already squashed)\n",
    "        gas (str)\n",
    "            -options are co2, ch4, n2o, co2e_100yr, co2e_20yr\n",
    "            -check the data CSV first before picking one!\n",
    "        distances (arr[int])\n",
    "            -array of desired distance thresholds\n",
    "        object_folder_path (str)\n",
    "            -path of folder to store the resultant pyg objects\n",
    "            \n",
    "    '''\n",
    "\n",
    "    # First load in the CSV and convert coords to numerical values\n",
    "    df['coords'] = df['st_astext'].apply(lambda x: loads(x).coords[0])\n",
    "\n",
    "    # Generate ID mapping for PyG convention and remap df IDs\n",
    "    unique_ids = df.asset_id.unique()\n",
    "    id_mapping = generate_id_mapping(unique_ids)\n",
    "    df['asset_id'] = df['asset_id'].apply(lambda x: id_mapping[x])\n",
    "\n",
    "    # Filter by desired gas if needed\n",
    "    if gas != None:\n",
    "        df = df[df['gas'] == gas]\n",
    "\n",
    "    # Generate pairs of form (ID #, (lat, lon))\n",
    "    id_coord_pairs = list(zip(df['asset_id'], df['coords']))\n",
    "    \n",
    "    # We will reformat and save these pairs for visualizations later!\n",
    "    node_coords = {}\n",
    "    for pair in id_coord_pairs:\n",
    "        node_coords[pair[0]] = pair[1]\n",
    "    torch.save(node_coords, object_folder_path + 'location-mapping')\n",
    "\n",
    "    # Make edge indices and save them locally\n",
    "    for distance in distances:\n",
    "        edge_index = connect_nodes(id_coord_pairs, distance)\n",
    "        path = object_folder_path + str(distance) + 'km'\n",
    "        torch.save(edge_index, path)\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get value counts of the 'Category' column\n",
    "value_counts = coal_ch4_emissions['asset_type'].value_counts()\n",
    "\n",
    "# Plot the bar chart\n",
    "value_counts.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Bar Chart of Category Counts')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oil and Gas Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will filter the dataset to a relevant subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_gas_df = pd.read_csv('data/fossil-fuels/asset_oil-and-gas-production-and-transport_emissions.csv')\n",
    "oil_gas_df['start_time'] = pd.to_datetime(oil_gas_df['start_time'])\n",
    "oil_gas_df['year'] = oil_gas_df['start_time'].dt.year\n",
    "oil_gas_df = oil_gas_df[  (oil_gas_df['year'] == 2021)\n",
    "                        & ((oil_gas_df['gas'] == 'co2') | (oil_gas_df['gas'] == 'ch4'))]\n",
    "oil_gas_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The oil and gas dataset contains emission quantities for two different gases (ch4 and co2) - we can use these both as features for classification and as labels for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch4_co2_vals = oil_gas_df.pivot(index='asset_id', columns='gas', values='emissions_quantity').reset_index()\n",
    "ch4_co2_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_gas_ch4_co2_df = pd.merge(oil_gas_df,\n",
    "                     ch4_co2_vals,\n",
    "                     on=['asset_id'])\n",
    "oil_gas_ch4_co2_df = oil_gas_ch4_co2_df.drop_duplicates(subset='asset_id') # we now have redundant duplicates since each row stores ch4 and co2 emission\n",
    "oil_gas_ch4_co2_df.head() # may need to scroll to the right to see ch4 and co2 stored!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = [1,2,3,4,5,25,50,100,200,500,1000,2000,5000,10000]\n",
    "oil_gas_ch4_co2_df = csv_to_data_and_edges(df=oil_gas_ch4_co2_df, distances=distances, object_folder_path='pyg_objects/oil+gas/co2+ch4-', gas=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get value counts of the 'Category' column\n",
    "value_counts = oil_gas_ch4_co2_df['asset_type'].value_counts()\n",
    "\n",
    "# Plot the bar chart\n",
    "value_counts.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Bar Chart of Category Counts')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can turn this dataframe into a PyG `Data` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.transforms import NormalizeFeatures, Compose\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "def cleaned_df_to_data(df, task, gases=None):\n",
    "    '''\n",
    "    Inputs:\n",
    "        df: \n",
    "            -the dataframe you have minus columns you do not intend to use in the Data object\n",
    "        task: \n",
    "            -'regression' or 'classification'\n",
    "        gases (optional): \n",
    "            -a list of gas names (str) if the data has multiple types of emission\n",
    "            -requires each emission to be stored in a column bearing the gas's name (`ch4`, `co2`, etc.) \n",
    "    Outputs:\n",
    "        data: a PyG `Data` object (with no edge index! added dynamically in testing)\n",
    "    '''\n",
    "\n",
    "    # We convert country of location to a categorical feature.\n",
    "    # The labels are adapted depending on the task.\n",
    "    if task == 'classification':\n",
    "        labels = torch.tensor(pd.factorize(df['asset_type'])[0])\n",
    "        df = df.drop(['asset_type'], axis=1)\n",
    "        df_cat = df[['iso3_country']]\n",
    "        dummies = pd.get_dummies(df_cat)\n",
    "        df = df.drop(['iso3_country'], axis=1)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "    else:\n",
    "        if gases != None:\n",
    "            labels = torch.tensor(df[gases].values)\n",
    "        else:\n",
    "            labels = torch.tensor(df['emissions_quantity'].values)\n",
    "        df_cat = df[['iso3_country', 'asset_type']]\n",
    "        dummies = pd.get_dummies(df_cat)\n",
    "        df = df.drop(['iso3_country', 'asset_type'], axis=1)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "    \n",
    "    df = df.astype(float)\n",
    "    features = torch.tensor(df.values)\n",
    "\n",
    "    permuted_indices = torch.randperm(labels.size(0))\n",
    "    labels = labels[permuted_indices]\n",
    "    features = features[permuted_indices]\n",
    "\n",
    "    data = Data(x=features, y=labels)\n",
    "\n",
    "    # Train and test masks\n",
    "    train_len = round(len(data.y) * 0.8) # 80% of total data will be for training \n",
    "    test_len = len(data.y) - train_len # the rest (20%) for testing\n",
    "\n",
    "    train_mask = ([True] * train_len) + ([False] * test_len) \n",
    "    test_mask = ([False] * train_len) + ([True] * test_len) \n",
    "\n",
    "    data.train_mask = torch.tensor(train_mask)\n",
    "    data.test_mask = torch.tensor(test_mask)\n",
    "\n",
    "    transform = T.NormalizeFeatures()\n",
    "    data = transform(data)\n",
    "\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_gas_ch4_co2_df = oil_gas_ch4_co2_df.drop(['asset_id', 'original_inventory_sector', 'start_time', 'end_time', \n",
    "                     'temporal_granularity', 'gas', 'emissions_quantity', 'emissions_factor_units', 'created_date', \n",
    "                     'modified_date', 'asset_name', 'st_astext', 'coords', 'year'], axis=1)\n",
    "oil_gas_ch4_co2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_gas_classification_data = cleaned_df_to_data(oil_gas_ch4_co2_df, 'classification', ['ch4','co2'])\n",
    "oil_gas_regression_data = cleaned_df_to_data(oil_gas_ch4_co2_df, 'regression', ['ch4','co2'])\n",
    "\n",
    "oil_gas_classification_data, oil_gas_regression_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(oil_gas_classification_data, 'pyg_objects/oil+gas/classification_data')\n",
    "torch.save(oil_gas_regression_data, 'pyg_objects/oil+gas/regression_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coal Mining Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = [1,2,3,4,5,25,50,100,200,500,1000,2000,5000,10000]\n",
    "coal_ch4_emissions = csv_to_data_and_edges(df=coal_ch4_emissions, distances=distances, object_folder_path='pyg_objects/coal/coal-ch4-edges-', gas=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coal_ch4_emissions = coal_ch4_emissions.drop(['asset_id', 'original_inventory_sector', 'start_time', 'end_time', \n",
    "                     'temporal_granularity', 'gas', 'emissions_factor_units',  'capacity_units', 'capacity', 'capacity_factor', \n",
    "                     'activity_units', 'created_date', 'modified_date', 'asset_name', 'st_astext', 'coords', 'lat_lon'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coal_classification_data = cleaned_df_to_data(coal_ch4_emissions, 'classification')\n",
    "coal_regression_data = cleaned_df_to_data(coal_ch4_emissions, 'regression')\n",
    "\n",
    "torch.save(coal_classification_data, 'pyg_objects/coal/coal_classification_data')\n",
    "torch.save(coal_regression_data, 'pyg_objects/coal/coal_regression_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics on Each Dataset\n",
    "\n",
    "Beginning with coal, we will see how many edges are present at each distance threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COAL DATASET\n",
      "1 km threshold: 452 edges\n",
      "2 km threshold: 968 edges\n",
      "3 km threshold: 1788 edges\n",
      "4 km threshold: 2772 edges\n",
      "5 km threshold: 3930 edges\n",
      "25 km threshold: 33032 edges\n",
      "50 km threshold: 74210 edges\n",
      "100 km threshold: 160670 edges\n",
      "200 km threshold: 348012 edges\n",
      "500 km threshold: 942714 edges\n",
      "1000 km threshold: 1348632 edges\n",
      "2000 km threshold: 1796560 edges\n",
      "5000 km threshold: 3927088 edges\n",
      "10000 km threshold: 5349564 edges\n",
      "OIL/GAS DATASET\n",
      "1 km threshold: 10 edges\n",
      "2 km threshold: 12 edges\n",
      "3 km threshold: 12 edges\n",
      "4 km threshold: 18 edges\n",
      "5 km threshold: 20 edges\n",
      "25 km threshold: 228 edges\n",
      "50 km threshold: 596 edges\n",
      "100 km threshold: 1446 edges\n",
      "200 km threshold: 3028 edges\n",
      "500 km threshold: 7192 edges\n",
      "1000 km threshold: 12312 edges\n",
      "2000 km threshold: 26152 edges\n",
      "5000 km threshold: 90260 edges\n",
      "10000 km threshold: 209010 edges\n"
     ]
    }
   ],
   "source": [
    "distances = [1,2,3,4,5,25,50,100,200,500,1000,2000,5000,10000]\n",
    "print(\"COAL DATASET\")\n",
    "for d in distances:\n",
    "    edges = torch.load('pyg_objects/coal/coal-ch4-edges-' + str(d) + 'km')\n",
    "    print(d, \"km threshold:\", edges.shape[-1], \"edges\")\n",
    "\n",
    "print(\"OIL/GAS DATASET\")\n",
    "for d in distances:\n",
    "    edges = torch.load('pyg_objects/oil+gas/co2+ch4-' + str(d) + 'km')\n",
    "    print(d, \"km threshold:\", edges.shape[-1], \"edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "import subprocess\n",
    "\n",
    "# Get a list of installed packages\n",
    "installed_packages = pkg_resources.working_set\n",
    "installed_packages_names = [pkg.project_name for pkg in installed_packages]\n",
    "\n",
    "# Get a list of imported packages in the notebook\n",
    "imported_packages = set()\n",
    "for line in open('node-connection.ipynb', 'r').readlines():\n",
    "    if 'import ' in line or 'from ' in line:\n",
    "        parts = line.split()\n",
    "        if len(parts) > 1:\n",
    "            imported_packages.add(parts[1].split('.')[0])\n",
    "\n",
    "# Filter the installed packages based on the imported packages\n",
    "filtered_packages = [package for package in installed_packages_names if package.lower() in imported_packages]\n",
    "\n",
    "# Generate the requirements.txt file\n",
    "with open('requirements.txt', 'w') as f:\n",
    "    for package in filtered_packages:\n",
    "        f.write(f\"{package}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
