{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.wkt import loads\n",
    "import torch_geometric\n",
    "import random \n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch_geometric.transforms as T\n",
    "import imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already normalized the data - we can create a second version of each `Data` object that contains self-loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have already normalized the data\n",
    "add_selfloops = T.AddSelfLoops()\n",
    "\n",
    "oil_gas_classification_data = torch.load('pyg_objects/oil+gas/classification_data')\n",
    "oil_gas_classification_data_selfloops = add_selfloops(oil_gas_classification_data)\n",
    "\n",
    "coal_classification_data = torch.load('pyg_objects/coal/coal_classification_data')\n",
    "coal_classification_data_selfloops = add_selfloops(coal_classification_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a fairly simple GCN for this task to more clearly analyze the effect of varying connectivity on accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(637)\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "        self.double()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "def gcn_train(model, data, optimizer, criterion):\n",
    "      model.train()\n",
    "      optimizer.zero_grad()  # Clear gradients.\n",
    "      out = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "      loss.backward()  # Derive gradients.\n",
    "      optimizer.step()  # Update parameters based on gradients.\n",
    "      return loss\n",
    "\n",
    "def gcn_test(model, data):\n",
    "      model.eval()\n",
    "      out = model(data.x, data.edge_index)\n",
    "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n",
    "      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n",
    "      return test_acc, pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_sweep(model, edges_path, data, optimizer, criterion, distances):\n",
    "    preds = []\n",
    "    accs = []\n",
    "    losses = []\n",
    "    \n",
    "    for distance in distances:     \n",
    "        optimizer.zero_grad()\n",
    "        filepath = edges_path + str(distance) + \"km\"\n",
    "        edges = torch.load(filepath)\n",
    "        data.edge_index = edges\n",
    "        print(len(edges[0]), 'edges')\n",
    "        for epoch in range(1, 500):\n",
    "                loss = gcn_train(model=model,\n",
    "                            data=data,\n",
    "                            optimizer=optimizer,\n",
    "                            criterion=criterion)\n",
    "                #print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "\n",
    "        test_acc, pred = gcn_test(model=model,\n",
    "                            data=data)\n",
    "        preds.append(pred)\n",
    "        accs.append(test_acc)\n",
    "        losses.append(loss)\n",
    "        print(distance, 'km',  test_acc, '%')\n",
    "\n",
    "    return preds, accs, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will test the accuracy of this model over a range of different connectivity thresholds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coal_model = GCN(in_channels=coal_classification_data.num_features, \n",
    "                hidden_channels=16,\n",
    "                out_channels=len(coal_classification_data.y.unique()))\n",
    "coal_optimizer = torch.optim.NAdam(coal_model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "coal_criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "distances =[1,2,3,4,5,25,50,100,200]\n",
    "coal_preds, coal_accs, coal_losses = dist_sweep(coal_model, 'pyg_objects/coal/coal-ch4-edges-', coal_classification_data, coal_optimizer, coal_criterion, distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carrying out the same test for the graph with selfloops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances =[1,2,3,4,5,25,50,100,200,500,1000]\n",
    "coal_preds_selfloops, coal_accs_selfloops, coal_losses_selfloops = dist_sweep(coal_model, 'pyg_objects/coal/coal-ch4-edges-', coal_classification_data_selfloops, coal_optimizer, coal_criterion, distances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_channels, output_dim):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(637)\n",
    "        self.lin1 = Linear(input_dim, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, output_dim)\n",
    "        self.double()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = x.relu()\n",
    "        x = self.lin2(x)\n",
    "        return x\n",
    "\n",
    "model = MLP(input_dim=coal_classification_data.num_features,\n",
    "            hidden_channels=16,\n",
    "            output_dim=4)\n",
    "optimizer = torch.optim.NAdam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, optimizer, criterion):\n",
    "      model.train()\n",
    "      optimizer.zero_grad()  # Clear gradients.\n",
    "      out = model(data.x)  # Perform a single forward pass.\n",
    "      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "      loss.backward()  # Derive gradients.\n",
    "      optimizer.step()  # Update parameters based on gradients.\n",
    "      return loss\n",
    "\n",
    "def test(model, data):\n",
    "      model.eval()\n",
    "      out = model(data.x)\n",
    "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n",
    "      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n",
    "      return test_acc\n",
    "\n",
    "\n",
    "for epoch in range(1, 2000):\n",
    "    loss = train(model, coal_classification_data, optimizer, criterion)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "\n",
    "test_acc = test(model, coal_classification_data)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(coal_accs, label = \"GCN accuracies\")\n",
    "plt.plot(coal_accs_selfloops, label=\"GCN w/ selfloops\")\n",
    "plt.xlabel('Edge Connectivity Threshold (km)')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.axhline(y=0.2904, color='r', linestyle='--', label='MLP accuracy')\n",
    "plt.xticks([0,1,2,3,4,5,6,7,8,9,10], [1,2,3,4,5,25,50,100,200,500,1000], fontsize=8)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic data upsampling to fix class imbalance\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "X_train = coal_classification_data.x[coal_classification_data.train_mask]\n",
    "y_train = coal_classification_data.y[coal_classification_data.train_mask]\n",
    "X_test = coal_classification_data.x[coal_classification_data.test_mask]\n",
    "y_test = coal_classification_data.y[coal_classification_data.test_mask]\n",
    "\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "\n",
    "X_resampled = torch.tensor(X_resampled)\n",
    "y_resampled = torch.tensor(y_resampled)\n",
    "\n",
    "coal_classification_data.x = torch.cat((X_resampled, X_test), dim=0)\n",
    "coal_classification_data.y = torch.cat((y_resampled, y_test), dim=0)\n",
    "\n",
    "# Train and test masks\n",
    "train_len = len(X_resampled)\n",
    "test_len = len(X_test)\n",
    "\n",
    "train_mask = ([True] * train_len) + ([False] * test_len) \n",
    "test_mask = ([False] * train_len) + ([True] * test_len) \n",
    "\n",
    "coal_classification_data.train_mask = torch.tensor(train_mask)\n",
    "coal_classification_data.test_mask = torch.tensor(test_mask)\n",
    "\n",
    "coal_classification_data_selfloops = add_selfloops(coal_classification_data)\n",
    "\n",
    "coal_model = GCN(in_channels=coal_classification_data.num_features, \n",
    "                hidden_channels=16,\n",
    "                out_channels=len(coal_classification_data.y.unique()))\n",
    "coal_optimizer = torch.optim.Adam(coal_model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "coal_criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "distances =[1,2,3,4,5,25,50,100,200]\n",
    "coal_preds, coal_accs, coal_losses = dist_sweep(coal_model, 'pyg_objects/coal/coal-ch4-edges-', coal_classification_data, coal_optimizer, coal_criterion, distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(input_dim=coal_classification_data.num_features,\n",
    "            hidden_channels=16,\n",
    "            output_dim=4)\n",
    "optimizer = torch.optim.NAdam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "for epoch in range(1, 2000):\n",
    "    loss = train(model, coal_classification_data, optimizer, criterion)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "\n",
    "test_acc = test(model, coal_classification_data)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oil/Gas Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_gas_classification_model = GCN(in_channels=oil_gas_classification_data.num_features, \n",
    "                hidden_channels=16,\n",
    "                out_channels=len(oil_gas_classification_data.y.unique()))\n",
    "oil_gas_classification_optimizer = torch.optim.NAdam(oil_gas_classification_model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "oil_gas_classification_criterion = torch.nn.CrossEntropyLoss()\n",
    "print(oil_gas_classification_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances =[1,2,3,4,5,25,50,100,200,500,1000,2000,5000,10000]\n",
    "oil_preds, oil_accs, oil_losses = dist_sweep(oil_gas_classification_model, 'pyg_objects/oil+gas/co2+ch4-', oil_gas_classification_data, oil_gas_classification_optimizer, oil_gas_classification_criterion, distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_selfloops, accs_selfloops, losses_selfloops = dist_sweep(oil_gas_classification_model, 'pyg_objects/oil+gas/co2+ch4-', \n",
    "                                             oil_gas_classification_data_selfloops, oil_gas_classification_optimizer, \n",
    "                                             oil_gas_classification_criterion, distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(input_dim=oil_gas_classification_data.num_features,\n",
    "            hidden_channels=16,\n",
    "            output_dim=4)\n",
    "optimizer = torch.optim.NAdam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "for epoch in range(1, 2000):\n",
    "    loss = train(model, oil_gas_classification_data, optimizer, criterion)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "\n",
    "test_acc = test(model, oil_gas_classification_data)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(oil_accs, label=\"GCN accuracies\")\n",
    "plt.plot(accs_selfloops, label=\"GCN w/ selfloops\")\n",
    "plt.axhline(y=0.6579, color='r', linestyle='--', label='MLP accuracy')\n",
    "plt.xlabel('Edge Connectivity Threshold (km)')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xticks([0,1,2,3,4,5,6,7,8,9,10,11,12,13], [1,2,3,4,5,25,50,100,200,500,1000,2000,5000,10000], fontsize=8)\n",
    "plt.title(\"Classification Accuracy on Oil/Gas Data\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_occurrences(tensor, target_number):\n",
    "    \"\"\"\n",
    "    Count the number of occurrences of a specific number in a PyTorch tensor.\n",
    "    \n",
    "    Parameters:\n",
    "        tensor (torch.Tensor): Input PyTorch tensor.\n",
    "        target_number: The number to count occurrences of.\n",
    "\n",
    "    Returns:\n",
    "        int: The number of occurrences of the target number in the tensor.\n",
    "    \"\"\"\n",
    "    # Create a boolean tensor indicating equality with the target number\n",
    "    equal_mask = torch.eq(tensor, target_number)\n",
    "\n",
    "    # Count the occurrences using torch.sum\n",
    "    occurrences = torch.sum(equal_mask).item()\n",
    "\n",
    "    return occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
